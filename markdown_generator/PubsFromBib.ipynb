{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Publications markdown generator for academicpages\n",
    "\n",
    "Takes a set of bibtex of publications and converts them for use with [academicpages.github.io](academicpages.github.io). This is an interactive Jupyter notebook ([see more info here](http://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/what_is_jupyter.html)). \n",
    "\n",
    "The core python code is also in `pubsFromBibs.py`. \n",
    "Run either from the `markdown_generator` folder after replacing updating the publist dictionary with:\n",
    "* bib file names\n",
    "* specific venue keys based on your bib file preferences\n",
    "* any specific pre-text for specific files\n",
    "* Collection Name (future feature)\n",
    "\n",
    "TODO: Make this work with other databases of citations, \n",
    "TODO: Merge this with the existing TSV parsing solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pybtex.database.input import bibtex\n",
    "import pybtex.database.input.bibtex \n",
    "from time import strptime\n",
    "import string\n",
    "import html\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo: incorporate different collection types rather than a catch all publications, requires other changes to template\n",
    "publist = {\n",
    "    \"conference\": {\n",
    "        \"file\" : \"conference.bib\",\n",
    "        \"venuekey\": \"booktitle\",\n",
    "        \"venue-pretext\": \"In the proceedings of \",\n",
    "        \"collection\" : {\"name\":\"publications/conference\",\n",
    "                        \"permalink\":\"/publication/conference\"},\n",
    "        \"outdir\" : \"../_publications/conference\"\n",
    "        \n",
    "    },\n",
    "    \"journal\":{\n",
    "        \"file\": \"journal_articles.bib\",\n",
    "        \"venuekey\" : \"journal\",\n",
    "        \"venue-pretext\" : \"\",\n",
    "        \"collection\" : {\"name\":\"publications/journal\",\n",
    "                        \"permalink\":\"/publication/journal\"},\n",
    "        \"outdir\" : \"../_publications/conference\"\n",
    "    }, \n",
    "    \"patents\":{\n",
    "        \"file\": \"patents.bib\",\n",
    "        \"venuekey\" : \"note\",\n",
    "        \"venue-pretext\" : \"\",\n",
    "        \"collection\" : {\"name\":\"publications\",\n",
    "                        \"permalink\":\"/publication/\"},\n",
    "        \"outdir\" : \"../_publications/\"\n",
    "    }, \n",
    "    \"talks\":{\n",
    "        \"file\": \"oral_presentations.bib\",\n",
    "        \"venuekey\" : \"note\",\n",
    "        \"venue-pretext\" : \"\",\n",
    "        \"collection\" : {\"name\":\"talks\",\n",
    "                        \"permalink\":\"/talks/\"},\n",
    "        \"outdir\" : \"../_talks/\"\n",
    "    },\n",
    "    \"posters\":{\n",
    "        \"file\": \"posters.bib\",\n",
    "        \"venuekey\" : \"note\",\n",
    "        \"venue-pretext\" : \"\",\n",
    "        \"collection\" : {\"name\":\"publications\",\n",
    "                        \"permalink\":\"/publication/\"},\n",
    "        \"outdir\" : \"../_publications/\"\n",
    "    },\n",
    "    \"preprints/submissions\":{\n",
    "        \"file\": \"preprints.bib\",\n",
    "        \"venuekey\" : \"journal\",\n",
    "        \"venue-pretext\" : \"\",\n",
    "        \"collection\" : {\"name\":\"publications\",\n",
    "                        \"permalink\":\"/publication/\"},\n",
    "        \"outdir\" : \"../_publications/\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_escape_table = {\n",
    "    \"&\": \"&amp;\",\n",
    "    '\"': \"&quot;\",\n",
    "    \"'\": \"&apos;\"\n",
    "    }\n",
    "\n",
    "def html_escape(text):\n",
    "    \"\"\"Produce entities within text.\"\"\"\n",
    "    return \"\".join(html_escape_table.get(c,c) for c in text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conference\n",
      "SUCESSFULLY PARSED goudey2013gwis: \" GWIS: model-free, fast and exhaustive search for epistatic i ... \"\n",
      "SUCESSFULLY PARSED goudey2011replication: \" Replication of epistatic DNA loci in two case-control GWAS s ... \"\n",
      "SUCESSFULLY PARSED reumann2012supercomputing: \" Supercomputing enabling exhaustive statistical analysis of g ... \"\n",
      "SUCESSFULLY PARSED wang2014gwis: \" GWIS FI: A universal GPU interface for exhaustive search of  ... \"\n",
      "SUCESSFULLY PARSED goudey2007exploring: \" Exploring Extensions to Machine-learning based Gene Normalis ... \"\n",
      "SUCESSFULLY PARSED yepes2018hybrid: \" A hybrid approach for automated mutation annotation of the e ... \"\n",
      "SUCESSFULLY PARSED reumann2011precision: \" Precision Medicine: Dawn of Supercomputing in ‘omics Researc ... \"\n",
      "journal\n",
      "SUCESSFULLY PARSED ye2024genetic: \" Genetic and environmental causes of variation in an automate ... \"\n",
      "SUCESSFULLY PARSED saint2023disease: \" Disease progression modelling of Alzheimer’s disease using p ... \"\n",
      "SUCESSFULLY PARSED chu2023can: \" How can we use mathematical modeling of amyloid-β in Alzheim ... \"\n",
      "SUCESSFULLY PARSED goudey2022propagation: \" Propagation, detection and correction of errors using the se ... \"\n",
      "SUCESSFULLY PARSED chen2022exploring: \" Exploring automatic inconsistency detection for literature-b ... \"\n",
      "SUCESSFULLY PARSED song2022binding: \" Binding Affinity Calculations of Gluten Peptides to HLA Risk ... \"\n",
      "SUCESSFULLY PARSED shafieibavani2021predictive: \" Predictive models for cochlear implant outcomes: Performance ... \"\n",
      "SUCESSFULLY PARSED erlichster2021pan: \" Pan-family assays for rapid viral screening: Reducing delays ... \"\n",
      "SUCESSFULLY PARSED goudey2021multicenter: \" A multicenter analysis of factors associated with hearing ou ... \"\n",
      "SUCESSFULLY PARSED trigos2021collateral: \" Collateral sensitivity to $\\beta$-lactam drugs in drug-resis ... \"\n",
      "SUCESSFULLY PARSED al2020novel: \" A novel haplotype-based eQTL approach identifies genetic ass ... \"\n",
      "SUCESSFULLY PARSED erlichster2021: \" Improved parsimony of genetic risk scores for coeliac diseas ... \"\n",
      "SUCESSFULLY PARSED al2020evaluation: \" Evaluation of consensus strategies for haplotype phasing  \"\n",
      "SUCESSFULLY PARSED meikle2011plasma: \" Plasma lipidomic analysis of stable and unstable coronary ar ... \"\n",
      "SUCESSFULLY PARSED bedHo2014stability: \" Stability of bivariate GWAS biomarker detection  \"\n",
      "SUCESSFULLY PARSED goudey2015high: \" High performance computing enabling exhaustive analysis of h ... \"\n",
      "SUCESSFULLY PARSED bedo2016information: \" Information theoretic alignment free variant calling  \"\n",
      "SUCESSFULLY PARSED macinnis2016use: \" Use of a novel nonparametric version of DEPTH to identify ge ... \"\n",
      "SUCESSFULLY PARSED goudey2017interactions: \" Interactions within the MHC contribute to the genetic archit ... \"\n",
      "SUCESSFULLY PARSED goudey2017framework: \" A framework for optimal health worker allocation in under-re ... \"\n",
      "SUCESSFULLY PARSED erlichster2019cross: \" Cross-ethnicity tagging SNPs for HLA alleles associated with ... \"\n",
      "SUCESSFULLY PARSED schmidt2018cirrus: \" Cirrus: an automated mammography-based measure of breast can ... \"\n",
      "SUCESSFULLY PARSED goudey2019blood: \" A blood-based signature of cerebrospinal fluid A $\\beta$ 1-- ... \"\n",
      "SUCESSFULLY PARSED al2019exploring: \" Exploring effective approaches for haplotype block phasing  \"\n",
      "SUCESSFULLY PARSED erlichster2020pan: \" Pan-Family Assays for Rapid Viral Screening: Reducing Delays ... \"\n",
      "SUCESSFULLY PARSED erlichster2020improved: \" Improved HLA-based prediction of coeliac disease identifies  ... \"\n",
      "patents\n",
      "SUCESSFULLY PARSED goudey2019mechanistic: \" Mechanistic mathematical model search engine  \"\n",
      "SUCESSFULLY PARSED meikle2020lipid: \" Lipid biomarkers for stable and unstable heart disease  \"\n",
      "SUCESSFULLY PARSED meikle2015lipid: \" Lipid biomarkers for stable and unstable heart disease  \"\n",
      "SUCESSFULLY PARSED kowalczyk2018identifying: \" Identifying interacting DNA loci using a contingency table,  ... \"\n",
      "SUCESSFULLY PARSED conway2019identifying: \" Identifying small scale variations across sets of bacterial  ... \"\n",
      "talks\n",
      "SUCESSFULLY PARSED goudey2020_meetup: \" Improving genetic testing of Celiac disease  \"\n",
      "SUCESSFULLY PARSED goudey2019bioinf: \" A bioinformatician in industrial research  \"\n",
      "SUCESSFULLY PARSED goudey2019b: \" Combining genetic risk scores and plasma proteins for a mini ... \"\n",
      "SUCESSFULLY PARSED goudey2019bb_adpd: \" Using blood-based protein biomarkers to predict CSF tau path ... \"\n",
      "SUCESSFULLY PARSED goudey2018celiacwehi: \" Improved prediction of celiac disease using known HLA risk h ... \"\n",
      "SUCESSFULLY PARSED goudey2017-bb-abacbs: \" A blood-based signature of cerebral spinal fluid A$\\beta$ st ... \"\n",
      "SUCESSFULLY PARSED goudey2017: \" Replication of interacting loci in celiac disease  \"\n",
      "SUCESSFULLY PARSED goudey2017bb-mdhs: \" A machine-learning derived plasma protein signature of cereb ... \"\n",
      "SUCESSFULLY PARSED goudey2013hisa: \" Enabling genome-wide search for multivariate biomarkers  \"\n",
      "SUCESSFULLY PARSED goudey2012ismb: \" Efficient detection of associated SNP pairs over multiple di ... \"\n",
      "SUCESSFULLY PARSED goudey2011amata: \" Replication of interacting DNA loci in case-control GWAS stu ... \"\n",
      "posters\n",
      "SUCESSFULLY PARSED chu2023developing: \" Developing a classifier to screen for mild cognitive impairm ... \"\n",
      "SUCESSFULLY PARSED liu2023machine: \" Machine learning composite of remote cognitive tests for scr ... \"\n",
      "SUCESSFULLY PARSED goudey2022understanding: \" Understanding the impact of PET amyloid cutpoints on prognos ... \"\n",
      "SUCESSFULLY PARSED saint2022evaluation: \" On the evaluation of disease progression modelling in Alzhei ... \"\n",
      "SUCESSFULLY PARSED fedyashov2022information: \" Information-theoretic approach to establishing optimal amylo ... \"\n",
      "SUCESSFULLY PARSED goudey2021survival-adpd: \" Accounting for interval-censoring in longitudinal Alzheimer' ... \"\n",
      "SUCESSFULLY PARSED goudey2019: \" Using blood-based protein biomarkers to predict CSF tau path ... \"\n",
      "SUCESSFULLY PARSED faux2018p1: \" The Combined Effect Of ApoE, BDNF, CSF A$\\beta$ and Ptau on  ... \"\n",
      "SUCESSFULLY PARSED goudey2018p1: \" A longitudinal analysis of the ATN staging criteria  \"\n",
      "SUCESSFULLY PARSED goudey2018-bb-adpd: \" A blood-based signature of cerebral spinal fluid A$\\beta$ st ... \"\n",
      "SUCESSFULLY PARSED goudey2017genomehash: \" Database-less Microbial Genotyping  \"\n",
      "SUCESSFULLY PARSED trigos2017lorne: \" An in-silico approach to narrow down drug combinations for p ... \"\n",
      "SUCESSFULLY PARSED goudey2016genomehash: \" GenomeHash - Database-less Microbial Genotyping  \"\n",
      "SUCESSFULLY PARSED Bedo2016KLvars: \" Information theoretic alignment-free variant calling  \"\n",
      "SUCESSFULLY PARSED goudey2013Lorne: \" GWIS: Fast and Exhaustive Search for Epistatic Interactions  ... \"\n",
      "SUCESSFULLY PARSED goudey2012ECCB: \" Commodity Platform for Genome Wide Interaction Search  \"\n",
      "preprints/submissions\n",
      "SUCESSFULLY PARSED Goudey2021HLAprox: \" ForestTyper: a machine learning approach for serotype predic ... \"\n",
      "SUCESSFULLY PARSED kiral2020ukbcc: \" UKBCC: a cohort curation package for UK Biobank  \"\n",
      "SUCESSFULLY PARSED goudey2021genomehash: \" GenomeHash: Database-less Microbial Genotyping  \"\n"
     ]
    }
   ],
   "source": [
    "for pubsource in publist:\n",
    "    print(pubsource)\n",
    "    parser = bibtex.Parser()\n",
    "    bibdata = parser.parse_file(publist[pubsource][\"file\"])\n",
    "    \n",
    "    #loop through the individual references in a given bibtex file\n",
    "    for bib_id in bibdata.entries:\n",
    "        #reset default date\n",
    "        pub_year = \"1900\"\n",
    "        pub_month = \"01\"\n",
    "        pub_day = \"01\"\n",
    "        \n",
    "        b = bibdata.entries[bib_id].fields\n",
    "        #print(b)\n",
    "        #print(\"\\n\\n\")\n",
    "        try:\n",
    "            pub_year = f'{b[\"year\"]}'\n",
    "\n",
    "            #todo: this hack for month and day needs some cleanup\n",
    "            if \"month\" in b.keys(): \n",
    "                if(len(b[\"month\"])<3):\n",
    "                    pub_month = \"0\"+b[\"month\"]\n",
    "                    pub_month = pub_month[-2:]\n",
    "                elif(b[\"month\"] not in range(12)):\n",
    "                    tmnth = strptime(b[\"month\"][:3],'%b').tm_mon   \n",
    "                    pub_month = \"{:02d}\".format(tmnth) \n",
    "                else:\n",
    "                    pub_month = str(b[\"month\"])\n",
    "            if \"day\" in b.keys(): \n",
    "                pub_day = str(b[\"day\"])\n",
    "\n",
    "                \n",
    "            pub_date = pub_year+\"-\"+pub_month+\"-\"+pub_day\n",
    "            \n",
    "            #strip out {} as needed (some bibtex entries that maintain formatting)\n",
    "            clean_title = b[\"title\"].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\").replace(\" \",\"-\")    \n",
    "\n",
    "            url_slug = re.sub(\"\\\\[.*\\\\]|[^a-zA-Z0-9_-]\", \"\", clean_title)\n",
    "            url_slug = url_slug.replace(\"--\",\"-\")\n",
    "\n",
    "            md_filename = (str(pub_date) + \"-\" + url_slug + \".md\").replace(\"--\",\"-\")\n",
    "            html_filename = (str(pub_date) + \"-\" + url_slug).replace(\"--\",\"-\")\n",
    "\n",
    "            #Build Citation from text\n",
    "            citation = \"\"\n",
    "\n",
    "            #citation authors - todo - add highlighting for primary author?\n",
    "            for author in bibdata.entries[bib_id].persons[\"author\"]:\n",
    "                #print(author)\n",
    "                citation = citation+\" \"+author.first_names[0]+\" \"+author.last_names[0]+\", \"\n",
    "\n",
    "            #citation title\n",
    "            citation = citation + \"\\\"\" + html_escape(b[\"title\"].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\")) + \".\\\"\"\n",
    "\n",
    "            #add venue logic depending on citation type\n",
    "            venue = publist[pubsource][\"venue-pretext\"]+b[publist[pubsource][\"venuekey\"]].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\")\n",
    "\n",
    "            citation = citation + \" \" + html_escape(venue)\n",
    "            citation = citation + \", \" + pub_year + \".\"\n",
    "\n",
    "            \n",
    "            ## YAML variables\n",
    "            md = \"---\\ntitle: \\\"\"   + html_escape(b[\"title\"].replace(\"{\", \"\").replace(\"}\",\"\").replace(\"\\\\\",\"\")) + '\"\\n'\n",
    "            \n",
    "            md += \"\"\"collection: \"\"\" +  publist[pubsource][\"collection\"][\"name\"]\n",
    "\n",
    "            md += \"\"\"\\npermalink: \"\"\" + publist[pubsource][\"collection\"][\"permalink\"]  + html_filename\n",
    "            \n",
    "            note = False\n",
    "            if \"note\" in b.keys():\n",
    "                if len(str(b[\"note\"])) > 5:\n",
    "                    md += \"\\nexcerpt: '\" + html_escape(b[\"note\"]) + \"'\"\n",
    "                    note = True\n",
    "\n",
    "            md += \"\\ndate: \" + str(pub_date) \n",
    "\n",
    "            md += \"\\nvenue: '\" + html_escape(venue) + \"'\"\n",
    "            \n",
    "            url = False\n",
    "            if \"url\" in b.keys():\n",
    "                if len(str(b[\"url\"])) > 5:\n",
    "                    md += \"\\npaperurl: '\" + b[\"url\"] + \"'\"\n",
    "                    url = True\n",
    "\n",
    "            md += \"\\ncitation: '\" + html_escape(citation) + \"'\"\n",
    "\n",
    "            md += \"\\n---\"\n",
    "\n",
    "            \n",
    "            ## Markdown description for individual page\n",
    "            if note:\n",
    "                md += \"\\n\" + html_escape(b[\"note\"]) + \"\\n\"\n",
    "\n",
    "            if url:\n",
    "                md += \"\\n[Access paper here](\" + b[\"url\"] + \"){:target=\\\"_blank\\\"}\\n\" \n",
    "            else:\n",
    "                md += \"\\nUse [Google Scholar](https://scholar.google.com/scholar?q=\"+html.escape(clean_title.replace(\"-\",\"+\"))+\"){:target=\\\"_blank\\\"} for full citation\"\n",
    "\n",
    "            md_filename = os.path.basename(md_filename)\n",
    "\n",
    "            with open(publist[pubsource][\"outdir\"] + md_filename, 'w') as f:\n",
    "                f.write(md)\n",
    "            print(f'SUCESSFULLY PARSED {bib_id}: \\\"', b[\"title\"][:60],\"...\"*(len(b['title'])>60),\"\\\"\")\n",
    "        # field may not exist for a reference\n",
    "        except KeyError as e:\n",
    "            print(f'WARNING Missing Expected Field {e} from entry {bib_id}: \\\"', b[\"title\"][:30],\"...\"*(len(b['title'])>30),\"\\\"\")\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jekyll_academic_bib_to_md",
   "language": "python",
   "name": "jekyll_academic_bib_to_md"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
